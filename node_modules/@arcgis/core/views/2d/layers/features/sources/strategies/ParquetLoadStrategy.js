/*
All material copyright ESRI, All Rights Reserved, unless otherwise specified.
See https://js.arcgis.com/4.33/esri/copyright.txt for details.
*/
import{throwIfAborted as e}from"../../../../../../core/promiseUtils.js";import{difference as t,union as i}from"../../../../../../core/SetUtils.js";import s from"../../../../../../layers/support/FieldsIndex.js";import{ParquetFile as a}from"../../../../../../libs/parquet/parquet.js";import{ALoadStrategy as r}from"./ALoadStrategy.js";import{FeatureSnapshotSourceChunk as l}from"./chunks/FeatureSnapshotSourceChunk.js";import{FeatureSetReaderJSON as o}from"../../support/FeatureSetReaderJSON.js";import{FeatureSetReaderParquet as n}from"../../support/FeatureSetReaderParquet.js";class d extends r{constructor(e,t,i,s){super(s),this._service=e,this._metadata=t,this._schema=i,this._chunkId=0,this._files=[],this._availableFields=new Set(i.mutable.availableFields);const{geometryInfo:a}=this._service;if("location"===a.encoding.type)this._availableFields.add(a.encoding.latitudeFieldName),this._availableFields.add(a.encoding.longitudeFieldName);else if(null!=a.encoding.multiscale&&a.encoding.multiscale.levels.length>=1){const e=a.encoding.multiscale.levels[0];this._availableFields.add(e.column)}else this._availableFields.add(a.encoding.primaryFieldName)}destroy(){for(const e of this._files)e.destroy()}get about(){return{supportsDisplayFilter:!1,willQueryAllFeatures:!0,willQueryFullResolutionGeometry:!0}}async updateFields(e){await this._promise;const s=new Set(e),a=t(s,this._availableFields);this._availableFields=i(a,this._availableFields),a.size&&await Promise.all(this._files.map((e=>{const t=Array.from(a).map((t=>e.metadata.getFieldIndex(t)));return e.inner.updateChunks(new Uint16Array(t))})))}async load(e){return null==this._promise&&(this._promise=this._download().then((()=>{this._loadHigherResGeometry()}))),this._promise}unload(e){}async addParquetFile(e){this._insert(e)}async _loadHigherResGeometry(){const{geometryInfo:e}=this._service;if("wkb"===e.encoding.type){if(!(null!=e.encoding.multiscale&&e.encoding.multiscale.levels.length>=1))return;await this.updateFields([e.encoding.primaryFieldName])}const t=Array.from(this._store.chunks());this._store.clear();for(const i of t)this._store.insert(i);this._store.refresh()}async _insert(t){const i=await a.create(t,{geometryInfo:this._service.geometryInfo,outSpatialReference:this._service.outSpatialReference,getCustomParameters:()=>this._schema.mutable.dataFilter.customParameters}),{geometryInfo:r}=this._service;e(this._options);const{fields:o,timeZoneByFieldName:d}=this._service.metadata.fieldsIndex,m=o.map((e=>({...e,index:i.metadata.getFieldIndex(e.name)}))),c=s.fromJSON({fields:m,timeZoneByFieldName:d}),h=new Uint16Array(Array.from(this._availableFields.values()).map((e=>c.get(e)?.index)).filter((e=>null!=e)));await i.inner.readChunksWithCallback(h,(e=>{const t=this._chunkId++,i=new n(this._metadata,c,r,e,t),s=new l(i,null,t,!1);this._store.insert(s)})),this._files.push(i)}async _download(){try{await Promise.all(this._service.source.urls.map((e=>this._insert(e))));const e=new l(o.empty(this._metadata),null,-1,!0);this._store.insert(e)}catch(e){throw console.error(e),e}}}export{d as ParquetLoadStrategy};
